{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from typing import Any\n",
    "\n",
    "from pydantic import BaseModel, RootModel, Field\n",
    "from pydantic_ai import Agent, RunContext\n",
    "\n",
    "agent = Agent(\"openai:gpt-4o-mini\", name=\"test_case_generator\", retries=1)\n",
    "\n",
    "@agent.system_prompt\n",
    "def test_case_system_prompt():\n",
    "    return \"\"\"You are a helpful test case generator. You will be given a description of functionality \n",
    "    and should generate test cases that thoroughly validate the described behavior.\n",
    "    \n",
    "    <TEST CASE OUTPUT FORMAT>\n",
    "    name: <name of the test case>\n",
    "    description: <description of the test case>\n",
    "    input: <input values for the test case>\n",
    "    expected_output: <expected output/behavior of the test case>\n",
    "    preconditions: <any relevant preconditions for the test case>\n",
    "    </TEST CASE OUTPUT FORMAT>\n",
    "\n",
    "    <OUTPUT FORMAT: list of dictionaries>\n",
    "    [<TEST CASE OUTPUT FORMAT>, <TEST CASE OUTPUT FORMAT>, ...]\n",
    "    </OUTPUT FORMAT>\n",
    "\n",
    "    Be aware of the number of test casaes the user wants and output the correct number of test cases in the correct output format.\n",
    "    \"\"\"\n",
    "\n",
    "agent.result_validator = lambda x: isinstance(x, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Agent.__init__() got an unexpected keyword argument 'aa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43maa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maa\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Agent.__init__() got an unexpected keyword argument 'aa'"
     ]
    }
   ],
   "source": [
    "\n",
    "Agent(aa=\"aa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_spec = {\n",
    "    \"paths\": {\n",
    "        \"/pets\": {\n",
    "            \"get\": {\n",
    "                \"parameters\": [\n",
    "                    {\n",
    "                        \"name\": \"status\",\n",
    "                        \"in\": \"query\",\n",
    "                        \"type\": \"string\",\n",
    "                        \"required\": True,\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            \"post\": {\n",
    "                \"operationId\": \"adoptPet\",\n",
    "                \"parameters\": [\n",
    "                    {\n",
    "                        \"name\": \"petId\",\n",
    "                        \"in\": \"query\", \n",
    "                        \"type\": \"string\",\n",
    "                        \"required\": True,\n",
    "                    }\n",
    "                ],\n",
    "                \"responses\": {\n",
    "                    \"200\": {\n",
    "                        \"description\": \"Pet adoption successful\",\n",
    "                        \"content\": {\n",
    "                            \"application/json\": {\n",
    "                                \"schema\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"message\": {\n",
    "                                            \"type\": \"string\"\n",
    "                                        },\n",
    "                                        \"adoptionId\": {\n",
    "                                            \"type\": \"string\"\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"post\": {\n",
    "                \"requestBody\": {\n",
    "                    \"content\": {\n",
    "                        \"application/json\": {\n",
    "                            \"schema\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"name\": {\"type\": \"string\"},\n",
    "                                    \"age\": {\"type\": \"integer\"},\n",
    "                                },\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.run(\"Generate one case for this API spec: \" + str(api_spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n    {\\n        \"name\": \"GetPetsByStatus\",\\n        \"description\": \"Validate that the API retrieves pets correctly based on their status.\",\\n        \"input\": {\\n            \"status\": \"available\"\\n        },\\n        \"expected_output\": {\\n            \"pets\": [\\n                {\\n                    \"name\": \"Buddy\",\\n                    \"age\": 3,\\n                    \"status\": \"available\"\\n                },\\n                {\\n                    \"name\": \"Max\",\\n                    \"age\": 2,\\n                    \"status\": \"available\"\\n                }\\n            ]\\n        },\\n        \"preconditions\": \"The API should have pets with the status \\'available\\' in the database.\"\\n    }\\n]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'description': 'Test retrieving a list of pets with a valid status',\n",
      "  'expected_output_json': None,\n",
      "  'expected_output_prompt': None,\n",
      "  'input_json': None,\n",
      "  'name': 'GetPetsByStatus',\n",
      "  'preconditions': 'The API server is running and has pets with status '\n",
      "                   \"'available' in the database.\"}]\n"
     ]
    }
   ],
   "source": [
    "class TestCase(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    input_json: dict[str, Any] | list[dict[str, Any]] | None = None\n",
    "    expected_output_prompt: str | None = None\n",
    "    expected_output_json: dict[str, Any] | list[dict[str, Any]] | None = None\n",
    "    preconditions: str | None = None\n",
    "\n",
    "class SuiteTestCases(RootModel[list[TestCase]]):\n",
    "    pass\n",
    "\n",
    "test_cases = SuiteTestCases.model_validate_json(response.data)\n",
    "\n",
    "pprint(test_cases.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning steps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```txt\n",
    "[User/Scenario Modeling] --> [Case Type Generator] --> [Data Expansion]  \n",
    "                                   |                        |  \n",
    "                                   v                        v  \n",
    "                        [Context-Aware Generator] --> [Synthetic Data Output]  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 User Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "class UserPersona(BaseModel):\n",
    "    persona_type: str\n",
    "    persona: str\n",
    "    primary_intentions: str\n",
    "    secondary_intentions: str\n",
    "\n",
    "user_modelling_agent = Agent(\n",
    "    \"openai:gpt-4o-mini\",\n",
    "    name=\"user_modelling_agent\", \n",
    "    retries=1,\n",
    "    result_type=list[UserPersona]\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MyDeps:  \n",
    "    known_users: str\n",
    "\n",
    "\n",
    "@user_modelling_agent.system_prompt\n",
    "\n",
    "def user_modelling_prompt(ctx: RunContext[MyDeps]) -> str:\n",
    "\n",
    "    return f\"\"\"\n",
    "    Role:\n",
    "    You are a strategic analyst tasked with identifying high-level user and service personas that may interact with an API or ML/AI system. Your goal is to surface potential users (both individual and service-level) and their general intentions for engaging with the system. You will work from a mix of known users and inferred personas, expanding the list to ensure diverse representation. The output should guide further development of detailed scenarios and workflows.\n",
    "\n",
    "    Objective:\n",
    "\n",
    "    Identify key user personas (e.g., developers, analysts, operators) and service personas (e.g., monitoring services, data ingestion pipelines).\n",
    "    Capture high-level intentions for each persona, representing their goals and types of interactions.\n",
    "    Expand known user/service types into broader categories to ensure full-spectrum coverage.\n",
    "    Distinguish between direct users (interacting directly with the API) and indirect users/services (operating through automated processes or third-party tools).\n",
    "    Instructions:\n",
    "\n",
    "    Persona Identification:\n",
    "    {\"The following users are known to interact with the system: \" + ctx.deps.known_users if ctx.deps.known_users is not None else ''}\n",
    "\n",
    "    Start with known user types or services that interact with the system.\n",
    "    Expand the list by identifying adjacent personas or services that share similar goals or operate in overlapping domains.\n",
    "    Consider both individual personas (e.g., data scientists, IT admins) and automated service personas (e.g., logging pipelines, monitoring tools).\n",
    "    Intent Mapping:\n",
    "\n",
    "    For each persona, identify primary intentions (e.g., data retrieval, model evaluation, anomaly detection).\n",
    "    Include secondary intentions (e.g., performance optimization, adversarial testing) to reflect edge or less common use cases.\n",
    "    Prioritize diverse goals that span operational, analytical, and exploratory use cases.\n",
    "    Abstraction Levels:\n",
    "\n",
    "    Keep intentions broad and conceptual (e.g., \"monitor system health,\" \"fetch analytics data\").\n",
    "    Avoid specific API endpoints or technical steps—focus on overarching objectives.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await user_modelling_agent.run(\n",
    "    \"Generate the user personas for this API spec: \" + str(api_spec),\n",
    "    deps=MyDeps(known_users=\"A young man who wants to adopt a pet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UserPersona(persona_type='Individual User', persona='Pet Adopter', primary_intentions='Explore available pets with specific statuses (e.g., available, adopted)', secondary_intentions='Learn about pet care and adoption processes'),\n",
      " UserPersona(persona_type='Individual User', persona='Pet Owner', primary_intentions='Update pet information such as name and age', secondary_intentions='Retrieve history of adopted pets or update status of pets'),\n",
      " UserPersona(persona_type='Developer', persona='API Integrator', primary_intentions='Integrate pet adoption API into applications for better user experience', secondary_intentions='Test endpoint functionalities for performance and reliability'),\n",
      " UserPersona(persona_type='Data Analyst', persona='Adoption Trend Analyst', primary_intentions='Analyze trends in pet adoptions based on status, age, and time periods', secondary_intentions='Generate reports on adoptions for stakeholders'),\n",
      " UserPersona(persona_type='Service', persona='Monitoring Service', primary_intentions='Monitor API uptime and response times for service availability', secondary_intentions='Alert relevant stakeholders in case of failures or performance issues'),\n",
      " UserPersona(persona_type='Service', persona='Logging Service', primary_intentions='Log API requests and responses for auditing and debugging purposes', secondary_intentions='Analyze logs for error patterns or unusual usage spikes')]\n"
     ]
    }
   ],
   "source": [
    "pprint(response.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test Case Family\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "class TestCaseFamily(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    test_case_type: str\n",
    "    test_variations: list[str]\n",
    "\n",
    "test_case_family_agent = Agent(\n",
    "    \"openai:gpt-4o-mini\",\n",
    "    name=\"test_case_family_agent\", \n",
    "    retries=1,\n",
    "    result_type=list[TestCaseFamily]\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TestCaseFamilyDeps:  \n",
    "    pass\n",
    "\n",
    "\n",
    "@test_case_family_agent.system_prompt\n",
    "def test_case_family_prompt(ctx: RunContext[TestCaseFamilyDeps]) -> str:\n",
    "    return f\"\"\"\n",
    "    Role:\n",
    "    You are a test case generation expert, responsible for expanding high-level user and service personas into detailed, diverse test cases. Your objective is to ensure the system is thoroughly validated across all types of scenarios, including normal workflows, edge cases, and stress tests. You anticipate potential system weaknesses by generating test cases that reflect both typical and extreme usage patterns.\n",
    "\n",
    "    Objective:\n",
    "\n",
    "    Generate detailed test cases covering normal, edge, and stress conditions for each persona or service.\n",
    "    Simulate realistic API interactions while ensuring exhaustive coverage of potential failure points.\n",
    "    Classify each test case by case type and expected outcome (e.g., success, failure, error handling).\n",
    "    Instructions:\n",
    "\n",
    "    Input Interpretation:\n",
    "\n",
    "    Take high-level personas and use cases as input (e.g., frontend developer fetching data, automated ETL pipelines).\n",
    "    For each persona or service, consider typical paths and potential deviations that may cause failures or inefficiencies.\n",
    "    Case Generation:\n",
    "\n",
    "    Normal Cases: Generate standard, expected interactions where the API functions as intended.\n",
    "    Edge Cases: Push boundaries by creating scenarios that test minimum/maximum values, invalid input formats, or unusual API sequences.\n",
    "    Stress Cases: Simulate high loads, frequent requests, or massive datasets to test system scalability and reliability.\n",
    "    Parameter Variation:\n",
    "\n",
    "    Generate test cases that vary API parameters, payload sizes, and data types to ensure broad coverage.\n",
    "    Account for dependency relationships between fields (e.g., date fields must follow logical order).\n",
    "    Classification:\n",
    "\n",
    "    Tag each test case with the appropriate category:\n",
    "    Normal – Routine, everyday interactions.\n",
    "    Edge – Boundary conditions or rare inputs.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_personas = response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TestCaseFamily(name='Explore Available Pets by Status - Normal Flow', description='The user searches for pets that are available for adoption using the specified status filter.', test_case_type='Normal', test_variations=['Search for pets available for adoption with filters (e.g., age, breed)', 'Search for pets that have been adopted', 'Search for pets with no filters applied']),\n",
      " TestCaseFamily(name='Explore Available Pets by Status - Edge Case', description='The user searches using extreme filters for pet availability using statuses that may not return any results.', test_case_type='Edge', test_variations=[\"Search for pets with a status that does not exist (e.g., 'lost')\", 'Search for pets with a very narrow breed filter that may return few to no results', 'Search for pets with an invalid age range (e.g., age 0 or -1)']),\n",
      " TestCaseFamily(name='Explore Available Pets by Status - Stress Test', description='The user performs multiple rapid searches for pets to test system response under high load.', test_case_type='Stress', test_variations=['Simultaneously search for pets available for adoption across different statuses (e.g., available, adopted) every 1 second for 10 minutes', 'Filter pets by various parameters continuously for an extended period', 'Conduct bulk searches by status with different combinations of filters (age, breed)']),\n",
      " TestCaseFamily(name='Learn About Pet Care - Normal Flow', description='The user accesses the pet care and adoption resources available on the platform.', test_case_type='Normal', test_variations=['View articles on pet care and tips for new adopters', 'Access resources on the adoption process and requirements', 'Open FAQs regarding pet care and adoption procedures']),\n",
      " TestCaseFamily(name='Learn About Pet Care - Edge Case', description='The user tries to access pet care resources using unusable input or edge conditions.', test_case_type='Edge', test_variations=['Attempt to search for pet care resources using an empty search term', 'Navigate to outdated or invalid resource links', 'Request information for a pet type that is not covered (e.g., exotic pets)']),\n",
      " TestCaseFamily(name='Learn About Pet Care - Stress Test', description='The user attempts to access pet care resources during high traffic periods, simulating peak usage.', test_case_type='Stress', test_variations=['Simultaneously request multiple pet care articles and resources to test page load time', 'Access resources repeatedly in quick succession to evaluate system durability', 'Perform high-volume searches for pet care tips to stress-test the platform'])]\n",
      "[TestCaseFamily(name='Update Pet Information - Normal Case', description='Update the name and age of a pet using valid input data.', test_case_type='Normal', test_variations=[\"Update with name 'Buddy' and age '5'\", \"Update with name 'Mittens' and age '3'\"]),\n",
      " TestCaseFamily(name='Retrieve Pet Adoption History - Normal Case', description='Retrieve the history of previously adopted pets without any errors.', test_case_type='Normal', test_variations=['Fetch adoption history for user with 2 adopted pets', 'Fetch adoption history for user with no adopted pets']),\n",
      " TestCaseFamily(name='Update Pet Status - Normal Case', description=\"Update the status of a pet to 'Adopted' successfully.\", test_case_type='Normal', test_variations=[\"Update status of pet 'Bella' to 'Adopted'\", \"Update status of pet 'Max' to 'In Foster Care'\"]),\n",
      " TestCaseFamily(name='Update Pet Information - Edge Case', description='Attempt to update pet information with boundary values, such as negative age or overly long name.', test_case_type='Edge', test_variations=[\"Update with name 'A' and age '-1'\", 'Update with name exceeding 50 characters']),\n",
      " TestCaseFamily(name='Retrieve Pet Adoption History - Edge Case', description='Fetch adoption history for invalid user IDs or nonexistent pets.', test_case_type='Edge', test_variations=['Fetch history for nonexistent user ID', 'Fetch adoption history for a pet that was never adopted']),\n",
      " TestCaseFamily(name='Update Pet Status - Edge Case', description='Update the status of non-existent pets or use invalid status values.', test_case_type='Edge', test_variations=['Update status of a pet that does not exist', \"Update a valid pet with an invalid status value like 'In Limbo'\"]),\n",
      " TestCaseFamily(name='Update Pet Information - Stress Case', description='Perform multiple updates to pet information in a short time frame to test system limits.', test_case_type='Stress', test_variations=['Update pet information 100 times in quick succession', 'Simultaneously update information for 10 different pets']),\n",
      " TestCaseFamily(name='Retrieve Pet Adoption History - Stress Case', description='Simulate high load by retrieving adoption history for multiple users simultaneously.', test_case_type='Stress', test_variations=['Fetch adoption history for 100 different users at once', 'Retrieve 1000 records of adoption history in one request']),\n",
      " TestCaseFamily(name='Update Pet Status - Stress Case', description='Update pet statuses for a large number of pets at once to test API limits.', test_case_type='Stress', test_variations=['Batch update statuses for 100 pets', 'Simultaneous status updates for 50 pets at a time'])]\n",
      "[TestCaseFamily(name='Basic Integration Test', description='Verify successful integration by making a GET request to fetch available pets for adoption.', test_case_type='Normal', test_variations=['GET /api/pets/available', 'Expected response contains list of available pets', 'Response time is under 2 seconds']),\n",
      " TestCaseFamily(name='Invalid Endpoint Test', description='Attempt to access an invalid endpoint to ensure proper error handling.', test_case_type='Edge', test_variations=['GET /api/pets/notfound', 'Expected response: 404 Not Found', 'Response time is under 1 second']),\n",
      " TestCaseFamily(name='Empty Query Parameter Test', description='Test retrieving pets with empty query parameters to check system behavior.', test_case_type='Edge', test_variations=['GET /api/pets?type=', 'Expected response: 400 Bad Request', 'Response message indicates missing parameters']),\n",
      " TestCaseFamily(name='Large Dataset Retrieval Test', description=\"Test the API's ability to handle requests for a large dataset by fetching multiple pages of pets.\", test_case_type='Stress', test_variations=['GET /api/pets?page=100', 'Expected response returns last page of pets', 'Total pets fetched is as expected with pagination']),\n",
      " TestCaseFamily(name='Concurrent Requests Test', description='Simulate multiple concurrent requests to test API performance under load.', test_case_type='Stress', test_variations=['Send 100 GET requests for available pets simultaneously', 'Expected response time for each request is under 1 second', 'Check for any timeouts or errors']),\n",
      " TestCaseFamily(name='Malformed JSON Test', description=\"Send malformed JSON in a POST request to test API's validation handling.\", test_case_type='Edge', test_variations=['POST /api/pets/adopt with invalid JSON structure', 'Expected response: 400 Bad Request', 'Response contains details about JSON formatting error']),\n",
      " TestCaseFamily(name='Authentication Failure Test', description='Attempt to access protected endpoints without authentication to verify security setup.', test_case_type='Edge', test_variations=['GET /api/pets/protected without token', 'Expected response: 401 Unauthorized', 'Verify that the system does not expose sensitive information']),\n",
      " TestCaseFamily(name='Performance Under Load Test', description='Measure response time and performance when fetching a large number of pets simultaneously.', test_case_type='Stress', test_variations=['GET /api/pets?limit=1000', 'Expected response under 5 seconds', 'Monitor server resource utilization'])]\n",
      "[TestCaseFamily(name='Normal Case 1: Fetch Pet Adoption Trends', description='The data analyst successfully fetches adoption trends based on specified parameters including status, age, and period.', test_case_type='Normal', test_variations=['Parameters: status=adopted, age=puppy, time_period=last_month', 'Parameters: status=adopted, age=senior, time_period=last_year', 'Parameters: status=all, age=kitten, time_period=current_week']),\n",
      " TestCaseFamily(name='Normal Case 2: Generate Adoption Report', description='A report is generated correctly for stakeholders with accurate data on pet adoption trends.', test_case_type='Normal', test_variations=['Time period: last_quarter', 'Status: adopted only', 'Age groups: 0-1 years, 1-5 years, 5+ years']),\n",
      " TestCaseFamily(name='Edge Case 1: Filter by Uncommon Age', description=\"The analyst tries to analyze adoption trends for a rarely adopted age category, such as 'unknown' age.\", test_case_type='Edge', test_variations=['Parameters: status=adopted, age=unknown, time_period=all', 'Parameters: status=adopted, age=oldest_age_category, time_period=current_year']),\n",
      " TestCaseFamily(name='Edge Case 2: Filter by Historical Data', description='Fetch adoption trends for a historical time period that may not have records.', test_case_type='Edge', test_variations=['Parameters: status=all, age=adult, time_period=2020', 'Parameters: status=not adopted, age=senior, time_period=2018']),\n",
      " TestCaseFamily(name='Stress Case 1: High Volume of Requests', description='Simulate the analyst making a high volume of requests for adoption data simultaneously.', test_case_type='Stress', test_variations=['Number of requests: 1000 in 1 minute, status=adopted, age=kitten', 'Number of requests: 500 simultaneous requests with varying periods and statuses']),\n",
      " TestCaseFamily(name='Stress Case 2: Large Dataset Retrieval', description='The analyst requests a large dataset for pet adoptions over an extended time period with multiple filters.', test_case_type='Stress', test_variations=['Parameters: status=all, age=any, time_period=10_years', 'Parameters: status=adopted, age=puppy, time_period=last_5_years with 100,000 records requested'])]\n",
      "[TestCaseFamily(name='Check API Uptime', description='Monitor the API status for uptime over a specified period.', test_case_type='Normal', test_variations=['Check uptime every minute for 24 hours', 'Check uptime every hourly for 7 days']),\n",
      " TestCaseFamily(name='Monitor API Response Times', description='Measure the response times of the API under normal conditions.', test_case_type='Normal', test_variations=['Capture response time for 100 consecutive requests', 'Monitor response time with different request payload sizes']),\n",
      " TestCaseFamily(name='Alert on API Failure', description='Confirm that alerts are sent when the API is down.', test_case_type='Normal', test_variations=['Simulate API downtime and check alert notifications', 'Ensure alerts are sent to multiple stakeholders upon API failure']),\n",
      " TestCaseFamily(name='Monitor High Response Time', description='Check if the system alerts on response times exceeding defined thresholds.', test_case_type='Edge', test_variations=['Simulate response times that take longer than 2 seconds', 'Test response time just above the threshold of acceptable performance']),\n",
      " TestCaseFamily(name='API Response with Invalid Data', description='Test how the monitoring service handles receiving invalid data responses from the API.', test_case_type='Edge', test_variations=['Inject invalid JSON into the API response', 'Simulate a scenario where the API responds with a 500 Internal Server Error']),\n",
      " TestCaseFamily(name='Simulate High Load on API', description='Stress test the monitoring service by simulating a high number of API requests.', test_case_type='Stress', test_variations=['Send 1000 requests per second to the API', 'Simulate a load test over an extended period of 1 hour']),\n",
      " TestCaseFamily(name='Recovery from API Downtime', description='Ensure that the service can recover and monitor the API after it comes back online.', test_case_type='Stress', test_variations=['Check monitoring status after a 10-minute downtime', 'Validate alerts after recovery from downtime'])]\n",
      "[TestCaseFamily(name='Log Request Normal Case', description='Log an API request with valid parameters and receive a success response.', test_case_type='Normal', test_variations=['Valid API request with all necessary headers and body', 'Valid API request hitting a performance threshold']),\n",
      " TestCaseFamily(name='Log Response Normal Case', description='Log an API response with valid parameters and ensure it is correctly stored.', test_case_type='Normal', test_variations=['Valid API response with all expected fields', 'Valid API response with a subset of fields']),\n",
      " TestCaseFamily(name='Log Request Edge Case - Invalid JSON', description='Send an API request with invalid JSON format to test error logging.', test_case_type='Edge', test_variations=['Malformed JSON in the request body', 'Empty JSON object in the request body']),\n",
      " TestCaseFamily(name='Log Response Edge Case - Empty Body', description='Receive an API response with an empty body and validate logging behavior.', test_case_type='Edge', test_variations=['API responds with a status code but empty body', 'API responds with error status code and empty body']),\n",
      " TestCaseFamily(name='Log Request Edge Case - Missing Headers', description='Try logging an API request missing required headers.', test_case_type='Edge', test_variations=['API request without authentication token header', 'API request without content type header']),\n",
      " TestCaseFamily(name='Log Request Stress Case - High Throughput', description='Simulate a high volume of API requests to test logging under stress.', test_case_type='Stress', test_variations=['1500 requests per minute', '5000 requests spread over 10 minutes']),\n",
      " TestCaseFamily(name='Log Response Stress Case - Large Payloads', description='Log responses with large payloads to test system limits and performance.', test_case_type='Stress', test_variations=['Responses with payload size of 10MB', 'Responses with payload size of 50MB']),\n",
      " TestCaseFamily(name='Analyze Logs for Error Patterns', description='Perform log analysis after introducing various error scenarios and monitor for detection accuracy.', test_case_type='Normal', test_variations=['Log entries with different error codes', 'Log entries with timestamps indicating unusual spikes']),\n",
      " TestCaseFamily(name='Analyze Logs Edge Case - Corrupted Log File', description='Test system response to a corrupted log file during analysis.', test_case_type='Edge', test_variations=['Log file missing entries', 'Log file with invalid format']),\n",
      " TestCaseFamily(name='Analyze Logs Stress Case - Massive Log Data', description='Simulate analysis of a massive dataset of logs to test performance and efficiency.', test_case_type='Stress', test_variations=['Analyze log entries over a year', 'Analyze logs with 1 million+ entries'])]\n"
     ]
    }
   ],
   "source": [
    "out_test_case_families_per_persona: dict[UserPersona, list[TestCaseFamily]] = dict()\n",
    "\n",
    "for user_persona in out_personas:\n",
    "    response = await test_case_family_agent.run(\n",
    "        \"Generate the test case families for this user persona: \" + str(user_persona),\n",
    "        deps=TestCaseFamilyDeps(known_users=user_persona)\n",
    "    )\n",
    "    out_test_case_families_per_persona[str(user_persona)] = response.data\n",
    "    pprint(response.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"persona_type='Individual User' persona='Pet Adopter' primary_intentions='Explore available pets with specific statuses (e.g., available, adopted)' secondary_intentions='Learn about pet care and adoption processes'\": [TestCaseFamily(name='Explore Available Pets by Status - Normal Flow', description='The user searches for pets that are available for adoption using the specified status filter.', test_case_type='Normal', test_variations=['Search for pets available for adoption with filters (e.g., age, breed)', 'Search for pets that have been adopted', 'Search for pets with no filters applied']),\n",
       "  TestCaseFamily(name='Explore Available Pets by Status - Edge Case', description='The user searches using extreme filters for pet availability using statuses that may not return any results.', test_case_type='Edge', test_variations=[\"Search for pets with a status that does not exist (e.g., 'lost')\", 'Search for pets with a very narrow breed filter that may return few to no results', 'Search for pets with an invalid age range (e.g., age 0 or -1)']),\n",
       "  TestCaseFamily(name='Explore Available Pets by Status - Stress Test', description='The user performs multiple rapid searches for pets to test system response under high load.', test_case_type='Stress', test_variations=['Simultaneously search for pets available for adoption across different statuses (e.g., available, adopted) every 1 second for 10 minutes', 'Filter pets by various parameters continuously for an extended period', 'Conduct bulk searches by status with different combinations of filters (age, breed)']),\n",
       "  TestCaseFamily(name='Learn About Pet Care - Normal Flow', description='The user accesses the pet care and adoption resources available on the platform.', test_case_type='Normal', test_variations=['View articles on pet care and tips for new adopters', 'Access resources on the adoption process and requirements', 'Open FAQs regarding pet care and adoption procedures']),\n",
       "  TestCaseFamily(name='Learn About Pet Care - Edge Case', description='The user tries to access pet care resources using unusable input or edge conditions.', test_case_type='Edge', test_variations=['Attempt to search for pet care resources using an empty search term', 'Navigate to outdated or invalid resource links', 'Request information for a pet type that is not covered (e.g., exotic pets)']),\n",
       "  TestCaseFamily(name='Learn About Pet Care - Stress Test', description='The user attempts to access pet care resources during high traffic periods, simulating peak usage.', test_case_type='Stress', test_variations=['Simultaneously request multiple pet care articles and resources to test page load time', 'Access resources repeatedly in quick succession to evaluate system durability', 'Perform high-volume searches for pet care tips to stress-test the platform'])],\n",
       " \"persona_type='Individual User' persona='Pet Owner' primary_intentions='Update pet information such as name and age' secondary_intentions='Retrieve history of adopted pets or update status of pets'\": [TestCaseFamily(name='Update Pet Information - Normal Case', description='Update the name and age of a pet using valid input data.', test_case_type='Normal', test_variations=[\"Update with name 'Buddy' and age '5'\", \"Update with name 'Mittens' and age '3'\"]),\n",
       "  TestCaseFamily(name='Retrieve Pet Adoption History - Normal Case', description='Retrieve the history of previously adopted pets without any errors.', test_case_type='Normal', test_variations=['Fetch adoption history for user with 2 adopted pets', 'Fetch adoption history for user with no adopted pets']),\n",
       "  TestCaseFamily(name='Update Pet Status - Normal Case', description=\"Update the status of a pet to 'Adopted' successfully.\", test_case_type='Normal', test_variations=[\"Update status of pet 'Bella' to 'Adopted'\", \"Update status of pet 'Max' to 'In Foster Care'\"]),\n",
       "  TestCaseFamily(name='Update Pet Information - Edge Case', description='Attempt to update pet information with boundary values, such as negative age or overly long name.', test_case_type='Edge', test_variations=[\"Update with name 'A' and age '-1'\", 'Update with name exceeding 50 characters']),\n",
       "  TestCaseFamily(name='Retrieve Pet Adoption History - Edge Case', description='Fetch adoption history for invalid user IDs or nonexistent pets.', test_case_type='Edge', test_variations=['Fetch history for nonexistent user ID', 'Fetch adoption history for a pet that was never adopted']),\n",
       "  TestCaseFamily(name='Update Pet Status - Edge Case', description='Update the status of non-existent pets or use invalid status values.', test_case_type='Edge', test_variations=['Update status of a pet that does not exist', \"Update a valid pet with an invalid status value like 'In Limbo'\"]),\n",
       "  TestCaseFamily(name='Update Pet Information - Stress Case', description='Perform multiple updates to pet information in a short time frame to test system limits.', test_case_type='Stress', test_variations=['Update pet information 100 times in quick succession', 'Simultaneously update information for 10 different pets']),\n",
       "  TestCaseFamily(name='Retrieve Pet Adoption History - Stress Case', description='Simulate high load by retrieving adoption history for multiple users simultaneously.', test_case_type='Stress', test_variations=['Fetch adoption history for 100 different users at once', 'Retrieve 1000 records of adoption history in one request']),\n",
       "  TestCaseFamily(name='Update Pet Status - Stress Case', description='Update pet statuses for a large number of pets at once to test API limits.', test_case_type='Stress', test_variations=['Batch update statuses for 100 pets', 'Simultaneous status updates for 50 pets at a time'])],\n",
       " \"persona_type='Developer' persona='API Integrator' primary_intentions='Integrate pet adoption API into applications for better user experience' secondary_intentions='Test endpoint functionalities for performance and reliability'\": [TestCaseFamily(name='Basic Integration Test', description='Verify successful integration by making a GET request to fetch available pets for adoption.', test_case_type='Normal', test_variations=['GET /api/pets/available', 'Expected response contains list of available pets', 'Response time is under 2 seconds']),\n",
       "  TestCaseFamily(name='Invalid Endpoint Test', description='Attempt to access an invalid endpoint to ensure proper error handling.', test_case_type='Edge', test_variations=['GET /api/pets/notfound', 'Expected response: 404 Not Found', 'Response time is under 1 second']),\n",
       "  TestCaseFamily(name='Empty Query Parameter Test', description='Test retrieving pets with empty query parameters to check system behavior.', test_case_type='Edge', test_variations=['GET /api/pets?type=', 'Expected response: 400 Bad Request', 'Response message indicates missing parameters']),\n",
       "  TestCaseFamily(name='Large Dataset Retrieval Test', description=\"Test the API's ability to handle requests for a large dataset by fetching multiple pages of pets.\", test_case_type='Stress', test_variations=['GET /api/pets?page=100', 'Expected response returns last page of pets', 'Total pets fetched is as expected with pagination']),\n",
       "  TestCaseFamily(name='Concurrent Requests Test', description='Simulate multiple concurrent requests to test API performance under load.', test_case_type='Stress', test_variations=['Send 100 GET requests for available pets simultaneously', 'Expected response time for each request is under 1 second', 'Check for any timeouts or errors']),\n",
       "  TestCaseFamily(name='Malformed JSON Test', description=\"Send malformed JSON in a POST request to test API's validation handling.\", test_case_type='Edge', test_variations=['POST /api/pets/adopt with invalid JSON structure', 'Expected response: 400 Bad Request', 'Response contains details about JSON formatting error']),\n",
       "  TestCaseFamily(name='Authentication Failure Test', description='Attempt to access protected endpoints without authentication to verify security setup.', test_case_type='Edge', test_variations=['GET /api/pets/protected without token', 'Expected response: 401 Unauthorized', 'Verify that the system does not expose sensitive information']),\n",
       "  TestCaseFamily(name='Performance Under Load Test', description='Measure response time and performance when fetching a large number of pets simultaneously.', test_case_type='Stress', test_variations=['GET /api/pets?limit=1000', 'Expected response under 5 seconds', 'Monitor server resource utilization'])],\n",
       " \"persona_type='Data Analyst' persona='Adoption Trend Analyst' primary_intentions='Analyze trends in pet adoptions based on status, age, and time periods' secondary_intentions='Generate reports on adoptions for stakeholders'\": [TestCaseFamily(name='Normal Case 1: Fetch Pet Adoption Trends', description='The data analyst successfully fetches adoption trends based on specified parameters including status, age, and period.', test_case_type='Normal', test_variations=['Parameters: status=adopted, age=puppy, time_period=last_month', 'Parameters: status=adopted, age=senior, time_period=last_year', 'Parameters: status=all, age=kitten, time_period=current_week']),\n",
       "  TestCaseFamily(name='Normal Case 2: Generate Adoption Report', description='A report is generated correctly for stakeholders with accurate data on pet adoption trends.', test_case_type='Normal', test_variations=['Time period: last_quarter', 'Status: adopted only', 'Age groups: 0-1 years, 1-5 years, 5+ years']),\n",
       "  TestCaseFamily(name='Edge Case 1: Filter by Uncommon Age', description=\"The analyst tries to analyze adoption trends for a rarely adopted age category, such as 'unknown' age.\", test_case_type='Edge', test_variations=['Parameters: status=adopted, age=unknown, time_period=all', 'Parameters: status=adopted, age=oldest_age_category, time_period=current_year']),\n",
       "  TestCaseFamily(name='Edge Case 2: Filter by Historical Data', description='Fetch adoption trends for a historical time period that may not have records.', test_case_type='Edge', test_variations=['Parameters: status=all, age=adult, time_period=2020', 'Parameters: status=not adopted, age=senior, time_period=2018']),\n",
       "  TestCaseFamily(name='Stress Case 1: High Volume of Requests', description='Simulate the analyst making a high volume of requests for adoption data simultaneously.', test_case_type='Stress', test_variations=['Number of requests: 1000 in 1 minute, status=adopted, age=kitten', 'Number of requests: 500 simultaneous requests with varying periods and statuses']),\n",
       "  TestCaseFamily(name='Stress Case 2: Large Dataset Retrieval', description='The analyst requests a large dataset for pet adoptions over an extended time period with multiple filters.', test_case_type='Stress', test_variations=['Parameters: status=all, age=any, time_period=10_years', 'Parameters: status=adopted, age=puppy, time_period=last_5_years with 100,000 records requested'])],\n",
       " \"persona_type='Service' persona='Monitoring Service' primary_intentions='Monitor API uptime and response times for service availability' secondary_intentions='Alert relevant stakeholders in case of failures or performance issues'\": [TestCaseFamily(name='Check API Uptime', description='Monitor the API status for uptime over a specified period.', test_case_type='Normal', test_variations=['Check uptime every minute for 24 hours', 'Check uptime every hourly for 7 days']),\n",
       "  TestCaseFamily(name='Monitor API Response Times', description='Measure the response times of the API under normal conditions.', test_case_type='Normal', test_variations=['Capture response time for 100 consecutive requests', 'Monitor response time with different request payload sizes']),\n",
       "  TestCaseFamily(name='Alert on API Failure', description='Confirm that alerts are sent when the API is down.', test_case_type='Normal', test_variations=['Simulate API downtime and check alert notifications', 'Ensure alerts are sent to multiple stakeholders upon API failure']),\n",
       "  TestCaseFamily(name='Monitor High Response Time', description='Check if the system alerts on response times exceeding defined thresholds.', test_case_type='Edge', test_variations=['Simulate response times that take longer than 2 seconds', 'Test response time just above the threshold of acceptable performance']),\n",
       "  TestCaseFamily(name='API Response with Invalid Data', description='Test how the monitoring service handles receiving invalid data responses from the API.', test_case_type='Edge', test_variations=['Inject invalid JSON into the API response', 'Simulate a scenario where the API responds with a 500 Internal Server Error']),\n",
       "  TestCaseFamily(name='Simulate High Load on API', description='Stress test the monitoring service by simulating a high number of API requests.', test_case_type='Stress', test_variations=['Send 1000 requests per second to the API', 'Simulate a load test over an extended period of 1 hour']),\n",
       "  TestCaseFamily(name='Recovery from API Downtime', description='Ensure that the service can recover and monitor the API after it comes back online.', test_case_type='Stress', test_variations=['Check monitoring status after a 10-minute downtime', 'Validate alerts after recovery from downtime'])],\n",
       " \"persona_type='Service' persona='Logging Service' primary_intentions='Log API requests and responses for auditing and debugging purposes' secondary_intentions='Analyze logs for error patterns or unusual usage spikes'\": [TestCaseFamily(name='Log Request Normal Case', description='Log an API request with valid parameters and receive a success response.', test_case_type='Normal', test_variations=['Valid API request with all necessary headers and body', 'Valid API request hitting a performance threshold']),\n",
       "  TestCaseFamily(name='Log Response Normal Case', description='Log an API response with valid parameters and ensure it is correctly stored.', test_case_type='Normal', test_variations=['Valid API response with all expected fields', 'Valid API response with a subset of fields']),\n",
       "  TestCaseFamily(name='Log Request Edge Case - Invalid JSON', description='Send an API request with invalid JSON format to test error logging.', test_case_type='Edge', test_variations=['Malformed JSON in the request body', 'Empty JSON object in the request body']),\n",
       "  TestCaseFamily(name='Log Response Edge Case - Empty Body', description='Receive an API response with an empty body and validate logging behavior.', test_case_type='Edge', test_variations=['API responds with a status code but empty body', 'API responds with error status code and empty body']),\n",
       "  TestCaseFamily(name='Log Request Edge Case - Missing Headers', description='Try logging an API request missing required headers.', test_case_type='Edge', test_variations=['API request without authentication token header', 'API request without content type header']),\n",
       "  TestCaseFamily(name='Log Request Stress Case - High Throughput', description='Simulate a high volume of API requests to test logging under stress.', test_case_type='Stress', test_variations=['1500 requests per minute', '5000 requests spread over 10 minutes']),\n",
       "  TestCaseFamily(name='Log Response Stress Case - Large Payloads', description='Log responses with large payloads to test system limits and performance.', test_case_type='Stress', test_variations=['Responses with payload size of 10MB', 'Responses with payload size of 50MB']),\n",
       "  TestCaseFamily(name='Analyze Logs for Error Patterns', description='Perform log analysis after introducing various error scenarios and monitor for detection accuracy.', test_case_type='Normal', test_variations=['Log entries with different error codes', 'Log entries with timestamps indicating unusual spikes']),\n",
       "  TestCaseFamily(name='Analyze Logs Edge Case - Corrupted Log File', description='Test system response to a corrupted log file during analysis.', test_case_type='Edge', test_variations=['Log file missing entries', 'Log file with invalid format']),\n",
       "  TestCaseFamily(name='Analyze Logs Stress Case - Massive Log Data', description='Simulate analysis of a massive dataset of logs to test performance and efficiency.', test_case_type='Stress', test_variations=['Analyze log entries over a year', 'Analyze logs with 1 million+ entries'])]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_test_case_families_per_persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Expanded Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(test_cases) for test_cases in out_test_case_families_per_persona.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Field' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTestCase\u001b[39;00m(BaseModel):\n\u001b[0;32m      4\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe name of the test case\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     description: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe description of the test case\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[96], line 4\u001b[0m, in \u001b[0;36mTestCase\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTestCase\u001b[39;00m(BaseModel):\n\u001b[1;32m----> 4\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mField\u001b[49m(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe name of the test case\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     description: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe description of the test case\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe path of the test case\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Field' is not defined"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "class TestCase(BaseModel):\n",
    "    name: str = Field(description=\"The name of the test case\")\n",
    "    description: str = Field(description=\"The description of the test case\")\n",
    "    path: str = Field(description=\"The path of the test case\")\n",
    "    method: str = Field(description=\"The method of the test case\")\n",
    "    input_json: dict[str, Any] | list[dict[str, Any]] | None = Field(description=\"The input values for the test case. Should strictly follow the api spec\")\n",
    "    expected_output_prompt: str | None = Field(description=\"The expected output/behavior of the test case\")\n",
    "    expected_output_json: dict[str, Any] | list[dict[str, Any]] | None = Field(description=\"The expected output/behavior of the test case\")\n",
    "    preconditions: str | None = Field(description=\"Any relevant preconditions for the test case\")\n",
    "\n",
    "\n",
    "test_case_generator_agent = Agent( \n",
    "    \"openai:gpt-4o-mini\",\n",
    "    name=\"test_case_generator_agent\", \n",
    "    retries=1,\n",
    "    result_type=list[TestCase]\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TestCaseGeneratorDeps:  \n",
    "    pass\n",
    "\n",
    "\n",
    "@test_case_generator_agent.system_prompt\n",
    "def test_case_generator_prompt(ctx: RunContext[TestCaseGeneratorDeps]) -> str:\n",
    "    return f\"\"\"\n",
    "    Role:\n",
    "    You are a data refinement and expansion specialist, responsible for ensuring wide parameter coverage and generating realistic, constraint-aware data for API and ML/AI testing. Your task is to take high-level test cases and enrich them by expanding parameter ranges, exploring edge values, and ensuring the data reflects real-world patterns and constraints.\n",
    "\n",
    "    Objective:\n",
    "\n",
    "    Expand test cases by generating diverse parameter values, ensuring broad coverage of normal, edge, and extreme conditions.\n",
    "    Apply realistic data constraints (e.g., date ranges, field dependencies) to avoid infeasible test scenarios.\n",
    "    Maximize variability across inputs while adhering to domain-specific logic and operational limits.\n",
    "    Instructions:\n",
    "\n",
    "    Parameter Expansion:\n",
    "\n",
    "    For each test case, vary key parameters (e.g., numeric ranges, string lengths, boolean flags).\n",
    "    Generate values across full ranges, including minimum, maximum, and boundary values.\n",
    "    Incorporate random sampling where appropriate to introduce variability.\n",
    "    Constraint Application:\n",
    "\n",
    "    Ensure expanded data respects logical dependencies (e.g., start_date must precede end_date).\n",
    "    Reflect real-world limits (e.g., phone numbers must follow local formats, user IDs must be alphanumeric).\n",
    "    Apply domain-specific constraints (e.g., healthcare data must pass validation rules, financial data must align with regulations).\n",
    "    Data Types and Formats:\n",
    "\n",
    "    Generate diverse formats for fields like dates, strings, and numerical values (e.g., ISO dates, various string encodings).\n",
    "    Vary payload sizes, testing both minimal and maximal inputs.\n",
    "    Edge and Adversarial Data:\n",
    "\n",
    "    Create inputs that test unusual conditions (e.g., empty payloads, long strings, nested JSON structures).\n",
    "    Ensure adversarial data (e.g., special characters, SQL injection patterns) is included to assess API security.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only expand first family\n",
    "\n",
    "out_test_case_families_per_persona[list(out_test_case_families_per_persona.keys())[0]]\n",
    "\n",
    "out_test_cases_per_family: dict[TestCaseFamily, list[TestCase]] = dict()\n",
    "\n",
    "for family in out_test_case_families_per_persona[list(out_test_case_families_per_persona.keys())[0]]:\n",
    "    response = await test_case_generator_agent.run(\n",
    "        f\"Expand the test case family of tests: {family.name}. This possible tests variations are: {family.test_variations}. The api spec is: {api_spec}\",\n",
    "        deps=TestCaseGeneratorDeps()\n",
    "    )\n",
    "    out_test_cases_per_family[family.name] = response.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestCase(name='Search for pets available for adoption with filters (age and breed)', description='Retrieve pets that are available for adoption filtered by specific age and breed criteria.', input_json={'status': 'available', 'age': 2, 'breed': 'Labrador'}, expected_output_prompt='A list of available pets filtered by age and breed.', expected_output_json=None, preconditions='User has access to the pet adoption API and the filtering criteria are valid.')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_test_cases_per_family[list(out_test_cases_per_family.keys())[0]][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_api(api_spec: dict):\n",
    "    \"\"\"\n",
    "    Creates a mock API implementation based on the provided OpenAPI specification.\n",
    "    \n",
    "    Args:\n",
    "        api_spec (dict): OpenAPI specification defining the API endpoints and schemas\n",
    "        \n",
    "    Returns:\n",
    "        dict: Mock API implementation with endpoint handlers\n",
    "    \"\"\"\n",
    "    # Initialize mock data store\n",
    "    mock_data = {\n",
    "        \"pets\": [\n",
    "            {\"id\": \"1\", \"name\": \"Buddy\", \"age\": 3, \"status\": \"available\"},\n",
    "            {\"id\": \"2\", \"name\": \"Max\", \"age\": 2, \"status\": \"available\"},\n",
    "            {\"id\": \"3\", \"name\": \"Luna\", \"age\": 1, \"status\": \"adopted\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    def get_pets(status: str = None):\n",
    "        \"\"\"Mock GET /pets endpoint\"\"\"\n",
    "        if status:\n",
    "            return {\"pets\": [pet for pet in mock_data[\"pets\"] if pet[\"status\"] == status]}\n",
    "        return {\"pets\": mock_data[\"pets\"]}\n",
    "    \n",
    "    def add_pet(name: str, age: int):\n",
    "        \"\"\"Mock POST /pets endpoint for adding new pets\"\"\"\n",
    "        new_pet = {\n",
    "            \"id\": str(len(mock_data[\"pets\"]) + 1),\n",
    "            \"name\": name,\n",
    "            \"age\": age,\n",
    "            \"status\": \"available\"\n",
    "        }\n",
    "        mock_data[\"pets\"].append(new_pet)\n",
    "        return new_pet\n",
    "        \n",
    "    def adopt_pet(pet_id: str):\n",
    "        \"\"\"Mock POST /pets endpoint for adopting pets\"\"\"\n",
    "        for pet in mock_data[\"pets\"]:\n",
    "            if pet[\"id\"] == pet_id and pet[\"status\"] == \"available\":\n",
    "                pet[\"status\"] = \"adopted\"\n",
    "                return {\n",
    "                    \"message\": f\"Successfully adopted pet {pet['name']}\",\n",
    "                    \"adoptionId\": f\"ADOPT-{pet_id}\"\n",
    "                }\n",
    "        return {\"error\": \"Pet not found or not available\"}\n",
    "    \n",
    "    return {\n",
    "        \"endpoints\": {\n",
    "            \"GET /pets\": get_pets,\n",
    "            \"POST /pets\": add_pet,\n",
    "            \"POST /pets/adopt\": adopt_pet\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "mock_api_instance = mock_api(api_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'The user searches for pets available for adoption filtering '\n",
      "                'by a specific age range (e.g., puppies under 1 year).',\n",
      " 'expected_output_json': None,\n",
      " 'expected_output_prompt': 'List of available pets under 1 year of age.',\n",
      " 'input_json': None,\n",
      " 'name': 'Normal Case - Search for available pets by age filter',\n",
      " 'preconditions': 'User is logged in and has access to the pet search '\n",
      "                  'function.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(out_test_cases_per_family[list(out_test_cases_per_family.keys())[0]][0].model_dump())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Inspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Agent(model=OpenAIModel(model_name='gpt-4o-mini'), name='test_case_generator', end_strategy='early', model_settings=None),\n",
       " Agent(model=OpenAIModel(model_name='gpt-4o-mini'), name='user_modelling_agent', end_strategy='early', model_settings=None),\n",
       " Agent(model=OpenAIModel(model_name='gpt-4o-mini'), name='test_case_family_agent', end_strategy='early', model_settings=None),\n",
       " Agent(model=OpenAIModel(model_name='gpt-4o-mini'), name='test_case_generator_agent', end_strategy='early', model_settings=None)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AgentInspector:\n",
    "    @staticmethod\n",
    "    def inspect_agent(agent: Agent) -> dict:\n",
    "        \"\"\"\n",
    "        Inspects an Agent instance and returns its key attributes and configuration.\n",
    "        \n",
    "        Args:\n",
    "            agent: An instance of Agent to inspect\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing agent attributes and configuration\n",
    "        \"\"\"\n",
    "        inspection_result = {\n",
    "            \"name\": agent.name,\n",
    "            \"model\": agent.model,\n",
    "            \"retries\": agent.retries,\n",
    "            \"result_type\": str(agent.result_type),\n",
    "            \"has_system_prompt\": hasattr(agent, \"system_prompt\"),\n",
    "        }\n",
    "        return inspection_result\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_agents() -> list[Agent]:\n",
    "        \"\"\"\n",
    "        Returns all Agent instances that have been created.\n",
    "        \n",
    "        Returns:\n",
    "            list[Agent]: List of all Agent instances\n",
    "        \"\"\"\n",
    "        return [obj for obj in globals().values() if isinstance(obj, Agent)]\n",
    "    \n",
    "AgentInspector.get_all_agents()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
